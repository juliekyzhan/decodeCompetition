{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4d8de-86cb-4bb2-bf89-db71c05c0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "from paths import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64c3adf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T15:24:23.709555Z",
     "start_time": "2025-08-04T15:24:23.696521Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b441eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T15:24:23.816906Z",
     "start_time": "2025-08-04T15:24:23.712603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 去重前数据检查 ===\n",
      "df_state_name原始行数: 156\n",
      "df_state_name中state_name的唯一值数量: 52\n",
      "\n",
      "=== 去重后数据检查 ===\n",
      "df_state_name去重后行数: 52\n",
      "df_state_name去重后state_name的唯一值数量: 52\n",
      "\n",
      "=== 清理后的数据样例 ===\n",
      "df_state_115中的NAME_clean前10个:\n",
      "['alabama', 'alaska', 'arizona', 'arkansas', 'california', 'colorado', 'connecticut', 'delaware', 'district of columbia', 'florida']\n",
      "\n",
      "df_state_name_unique中的state_name_clean前10个:\n",
      "['alaska', 'alabama', 'arkansas', 'colorado', 'district of columbia', 'georgia', 'iowa', 'idaho', 'illinois', 'kansas']\n",
      "\n",
      "=== 合并结果 ===\n",
      "合并前df_state_115行数: 52\n",
      "合并后行数: 52\n",
      "\n",
      "匹配上的记录数: 52\n",
      "未匹配上的记录数: 0\n",
      "总记录数: 52\n",
      "匹配率: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\29087\\AppData\\Local\\Temp\\ipykernel_86216\\1395492874.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_state_name_unique['state_name_clean'] = df_state_name_unique['state_name'].str.strip().str.lower()\n"
     ]
    }
   ],
   "source": [
    "# 重新加载原始数据\n",
    "df_state_115 = pd.read_csv(DATA_DIR / \"final_state_115_0803.csv\")\n",
    "df_state_name = pd.read_excel(DATA_DIR / \"州名和州码.xlsx\")\n",
    "\n",
    "print(\"=== 去重前数据检查 ===\")\n",
    "print(f\"df_state_name原始行数: {len(df_state_name)}\")\n",
    "print(f\"df_state_name中state_name的唯一值数量: {df_state_name['state_name'].nunique()}\")\n",
    "\n",
    "# 对df_state_name按state_name去重，保留第一条记录\n",
    "df_state_name_unique = df_state_name.drop_duplicates(subset=['state_name'], keep='first')\n",
    "\n",
    "print(f\"\\n=== 去重后数据检查 ===\")\n",
    "print(f\"df_state_name去重后行数: {len(df_state_name_unique)}\")\n",
    "print(f\"df_state_name去重后state_name的唯一值数量: {df_state_name_unique['state_name'].nunique()}\")\n",
    "\n",
    "# 统一大小写和格式，提高匹配率\n",
    "df_state_115['NAME_clean'] = df_state_115['NAME'].str.strip().str.lower()\n",
    "df_state_name_unique['state_name_clean'] = df_state_name_unique['state_name'].str.strip().str.lower()\n",
    "\n",
    "print(f\"\\n=== 清理后的数据样例 ===\")\n",
    "print(\"df_state_115中的NAME_clean前10个:\")\n",
    "print(df_state_115['NAME_clean'].head(10).tolist())\n",
    "print(\"\\ndf_state_name_unique中的state_name_clean前10个:\")\n",
    "print(df_state_name_unique['state_name_clean'].head(10).tolist())\n",
    "\n",
    "# 执行合并，使用清理后的字段\n",
    "df_state_115_merged = df_state_115.merge(\n",
    "    df_state_name_unique,\n",
    "    left_on='NAME_clean',\n",
    "    right_on='state_name_clean',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n=== 合并结果 ===\")\n",
    "print(f\"合并前df_state_115行数: {len(df_state_115)}\")\n",
    "print(f\"合并后行数: {len(df_state_115_merged)}\")\n",
    "\n",
    "# 统计匹配情况\n",
    "if 'state_code' in df_state_115_merged.columns:\n",
    "    matched_count = df_state_115_merged['state_code'].notna().sum()\n",
    "    unmatched_count = df_state_115_merged['state_code'].isna().sum()\n",
    "    total_count = len(df_state_115_merged)\n",
    "\n",
    "    print(f\"\\n匹配上的记录数: {matched_count}\")\n",
    "    print(f\"未匹配上的记录数: {unmatched_count}\")\n",
    "    print(f\"总记录数: {total_count}\")\n",
    "    print(f\"匹配率: {matched_count / total_count * 100:.2f}%\")\n",
    "\n",
    "    # 查看未匹配的州名\n",
    "    if unmatched_count > 0:\n",
    "        print(f\"\\n未匹配的州名:\")\n",
    "        unmatched_states = df_state_115_merged[df_state_115_merged['state_code'].isna()]['NAME'].unique()\n",
    "        for state in unmatched_states:\n",
    "            print(f\"  - {state}\")\n",
    "\n",
    "# 删除临时的清理列\n",
    "df_state_115_merged = df_state_115_merged.drop(columns=['NAME_clean', 'state_name_clean'])\n",
    "\n",
    "# 更新df_state_115\n",
    "df_state_115 = df_state_115_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba77f6cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T15:24:23.824513Z",
     "start_time": "2025-08-04T15:24:23.817421Z"
    }
   },
   "outputs": [],
   "source": [
    "df_state_115.to_csv(DATA_DIR / \"state_115_1220_with_codes.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
