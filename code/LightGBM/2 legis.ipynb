{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f8801bf",
   "metadata": {},
   "source": [
    "# 兑现模式下的特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c55d5a-8610-4ac4-b5c1-1962a66c3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths\n",
    "from paths import DATA_DIR, TRAIN_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e869e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需库\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import psycopg2\n",
    "from itertools import product\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c790e",
   "metadata": {},
   "source": [
    "## 1. 数据获取\n",
    "### 1.1 获取兑现样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a7db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_data = pd.read_csv(DATA_DIR / \"115-118_congress_data.csv\")\n",
    "cash_members = pd.read_csv(DATA_DIR / \"议员选区数据.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6310519d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 兑现数据过滤分析 ===\n",
      "原始cash_data规模: (154651, 6)\n",
      "cash_members规模: (15251, 5)\n",
      "有效的议员-国会届次组合数: 15236\n",
      "cash_data中的议员-国会届次组合数: 2594\n",
      "无效的议员-国会届次组合数: 0\n",
      "过滤后cash_data规模: (154651, 6)\n",
      "删除的记录数: 0\n",
      "保留率: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def filter_cash_data_by_members(cash_data, cash_members):\n",
    "    \"\"\"\n",
    "    根据cash_members中的数据过滤cash_data，只保留有效的议员-国会届次组合\n",
    "    \n",
    "    参数:\n",
    "    cash_data: 包含'congress', 'mid'等列的DataFrame\n",
    "    cash_members: 包含'bioguide_id', 'congress'等列的DataFrame\n",
    "    \n",
    "    返回:\n",
    "    过滤后的cash_data DataFrame\n",
    "    \"\"\"\n",
    "    print(\"=== 兑现数据过滤分析 ===\")\n",
    "    print(f\"原始cash_data规模: {cash_data.shape}\")\n",
    "    print(f\"cash_members规模: {cash_members.shape}\")\n",
    "    \n",
    "    # 1. 创建有效的议员-国会届次组合集合\n",
    "    valid_combinations = set(zip(cash_members['bioguide_id'], cash_members['congress']))\n",
    "    print(f\"有效的议员-国会届次组合数: {len(valid_combinations)}\")\n",
    "    \n",
    "    # 2. 为cash_data创建对应的组合\n",
    "    cash_data_combinations = set(zip(cash_data['mid'], cash_data['congress']))\n",
    "    print(f\"cash_data中的议员-国会届次组合数: {len(cash_data_combinations)}\")\n",
    "    \n",
    "    # 3. 找出无效的组合\n",
    "    invalid_combinations = cash_data_combinations - valid_combinations\n",
    "    print(f\"无效的议员-国会届次组合数: {len(invalid_combinations)}\")\n",
    "    \n",
    "    # 4. 创建过滤条件\n",
    "    filter_condition = cash_data.apply(\n",
    "        lambda row: (row['mid'], row['congress']) in valid_combinations, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 5. 应用过滤\n",
    "    filtered_data = cash_data[filter_condition].copy()\n",
    "    \n",
    "    print(f\"过滤后cash_data规模: {filtered_data.shape}\")\n",
    "    print(f\"删除的记录数: {len(cash_data) - len(filtered_data)}\")\n",
    "    print(f\"保留率: {len(filtered_data) / len(cash_data) * 100:.2f}%\")\n",
    "    \n",
    "    # # 6. 详细分析被过滤的数据\n",
    "    # if len(cash_data) > len(filtered_data):\n",
    "    #     removed_data = cash_data[~filter_condition]\n",
    "    #     print(f\"\\n=== 被过滤数据分析 ===\")\n",
    "    #     print(\"按国会届次分布:\")\n",
    "    #     print(removed_data['congress'].value_counts().sort_index())\n",
    "    #     print(\"\\n按议员ID分布(前10):\")\n",
    "    #     print(removed_data['mid'].value_counts().head(10))\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "# 应用过滤函数\n",
    "cash_data_filtered = filter_cash_data_by_members(cash_data, cash_members)\n",
    "\n",
    "# # 验证过滤结果\n",
    "# print(f\"\\n=== 过滤结果验证 ===\")\n",
    "# print(\"过滤前cash_data的congress分布:\")\n",
    "# print(cash_data['congress'].value_counts().sort_index())\n",
    "# print(\"\\n过滤后cash_data的congress分布:\")\n",
    "# print(cash_data_filtered['congress'].value_counts().sort_index())\n",
    "\n",
    "# 更新cash_data变量\n",
    "cash_data = cash_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f10801fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>introduced_date</th>\n",
       "      <th>mid</th>\n",
       "      <th>issue</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>2019-05-15</td>\n",
       "      <td>D000216</td>\n",
       "      <td>Agriculture and Food</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>H001085</td>\n",
       "      <td>Agriculture and Food</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119</td>\n",
       "      <td>2025-03-03</td>\n",
       "      <td>S001220</td>\n",
       "      <td>Agriculture and Food</td>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress introduced_date      mid                 issue  year  month\n",
       "0       116      2019-05-15  D000216  Agriculture and Food  2019      5\n",
       "1       119      2025-03-03  H001085  Agriculture and Food  2025      3\n",
       "2       119      2025-03-03  S001220  Agriculture and Food  2025      3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525a1a0",
   "metadata": {},
   "source": [
    "## 2. 构造正负样本\n",
    "### 2.1 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a73463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "congress\n",
       "117    46283\n",
       "118    45920\n",
       "116    40213\n",
       "115    14162\n",
       "119     8073\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cash_data['congress'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e8583f",
   "metadata": {},
   "source": [
    "### 2.2 创建样本生成函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "953207a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples_from_cash_data_v6(cash_data):\n",
    "    \"\"\"\n",
    "    基于cash_data构建正负样本 (修改版v6)\n",
    "    \n",
    "    正样本：cash_data中每个议员在每届congress中选择的议题（去重并统计次数）\n",
    "    负样本：针对每一届congress，议员没有选择的议题\n",
    "    \n",
    "    参数:\n",
    "    cash_data: DataFrame，包含congress, year, month, mid, issue列\n",
    "    \n",
    "    返回:\n",
    "    train_df: 包含所有正负样本的DataFrame，date列存储JSON格式的详细信息\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "    \n",
    "    # 定义所有可能的议题\n",
    "    all_issues = [\n",
    "        'Agriculture and Food', 'Armed Forces', 'National Security',\n",
    "        'Art, Culture, Religion',\n",
    "        'civil rights and liberties, minority issues', 'Commerce',\n",
    "        'Congressional political operations', 'Crime and Law enforcement',\n",
    "        'economics and public finance', 'education',\n",
    "        'emergency management', 'energy', 'environmental protection',\n",
    "        'finance and financial sector', 'international trade',\n",
    "        'international finance', 'government operations and politics',\n",
    "        'health', 'Housing and Community Development', 'immigration',\n",
    "        'alliance and collective security', 'human rights',\n",
    "        'foreign affairs', 'labor and employment', 'law',\n",
    "        'public lands and natural resources',\n",
    "        'science, technology, communications',\n",
    "        'social science and history', 'social welfare', 'taxation',\n",
    "        'transportation and public works', 'water resources development'\n",
    "    ]\n",
    "    \n",
    "    print(f\"议题总数: {len(all_issues)}\")\n",
    "    \n",
    "    # 1. 按congress分组处理\n",
    "    congress_groups = cash_data.groupby('congress')\n",
    "    \n",
    "    for congress, group in congress_groups:\n",
    "        print(f\"\\n处理第 {congress} 届congress...\")\n",
    "        \n",
    "        # 按议员分组，获取每个议员在该届congress中选择的议题信息\n",
    "        member_groups = group.groupby('mid')\n",
    "        \n",
    "        congress_positive = 0\n",
    "        congress_negative = 0\n",
    "        \n",
    "        for mid, member_data in member_groups:\n",
    "            # 2. 统计该议员在该届congress中每个议题的选择情况\n",
    "            issue_stats = {}\n",
    "            \n",
    "            # 按议题分组，统计次数和收集日期信息\n",
    "            issue_groups = member_data.groupby('issue')\n",
    "            for issue, issue_data in issue_groups:\n",
    "                # 统计该议题的选择次数\n",
    "                count = len(issue_data)\n",
    "                \n",
    "                # 收集所有相关的日期信息\n",
    "                dates_info = []\n",
    "                for _, row in issue_data.iterrows():\n",
    "                    dates_info.append({\n",
    "                        'year': int(row['year']),\n",
    "                        'month': int(row['month'])\n",
    "                    })\n",
    "                \n",
    "                # 存储该议题的完整信息\n",
    "                issue_stats[issue] = {\n",
    "                    'count': count,\n",
    "                    'dates': dates_info,\n",
    "                    'first_date': f\"{dates_info[0]['year']}-{dates_info[0]['month']:02d}\",\n",
    "                    'congress': int(congress)\n",
    "                }\n",
    "            \n",
    "            # 3. 构建正样本：该议员选择的每个议题\n",
    "            for issue, stats in issue_stats.items():\n",
    "                # 将统计信息转换为JSON字符串\n",
    "                date_json = json.dumps(stats, ensure_ascii=False)\n",
    "                \n",
    "                positive_samples.append([\n",
    "                    congress,\n",
    "                    issue,\n",
    "                    mid,\n",
    "                    1,  # 正样本标签\n",
    "                    date_json  # JSON格式的日期和统计信息\n",
    "                ])\n",
    "                congress_positive += 1\n",
    "            \n",
    "            # 4. 构建负样本：该议员未选择的议题\n",
    "            selected_issues = set(issue_stats.keys())\n",
    "            unselected_issues = set(all_issues) - selected_issues\n",
    "            \n",
    "            for issue in unselected_issues:\n",
    "                # 负样本的JSON信息（没有实际选择记录）\n",
    "                negative_info = {\n",
    "                    'count': 0,\n",
    "                    'dates': [],\n",
    "                    'first_date': None,\n",
    "                    'congress': int(congress)\n",
    "                }\n",
    "                date_json = json.dumps(negative_info, ensure_ascii=False)\n",
    "                \n",
    "                negative_samples.append([\n",
    "                    congress,\n",
    "                    issue,\n",
    "                    mid,\n",
    "                    0,  # 负样本标签\n",
    "                    date_json\n",
    "                ])\n",
    "                congress_negative += 1\n",
    "        \n",
    "        print(f\"第 {congress} 届congress - 正样本: {congress_positive}, 负样本: {congress_negative}\")\n",
    "    \n",
    "    print(f\"\\n=== 总体统计 ===\")\n",
    "    print(f\"总正样本数量: {len(positive_samples)}\")\n",
    "    print(f\"总负样本数量: {len(negative_samples)}\")\n",
    "    print(f\"总样本数量: {len(positive_samples) + len(negative_samples)}\")\n",
    "    print(f\"正负样本比例: 1:{len(negative_samples)/len(positive_samples):.1f}\")\n",
    "    \n",
    "    # 转换为DataFrame\n",
    "    columns = ['congress', 'issue', 'mid', 'label', 'date']\n",
    "    positive_df = pd.DataFrame(positive_samples, columns=columns)\n",
    "    negative_df = pd.DataFrame(negative_samples, columns=columns)\n",
    "    \n",
    "    # 合并所有样本\n",
    "    train_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
    "    \n",
    "    # 随机打乱数据\n",
    "    train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3059e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 使用新版本函数\n",
    "# cash_data = pd.read_csv(\"./input/115-118_congress_data.csv\")\n",
    "\n",
    "# print(f\"Cash data 原始规模: {len(cash_data)} 行\")\n",
    "# print(f\"时间范围: {cash_data['year'].min()}-{cash_data['year'].max()}\")\n",
    "# print(f\"议员数量: {cash_data['mid'].nunique()}\")\n",
    "# print(f\"议题数量: {cash_data['issue'].nunique()}\")\n",
    "\n",
    "# # 创建完整的训练数据集（JSON格式）\n",
    "# train_df_v6 = create_samples_from_ca\n",
    "# sh_data_v6(cash_data)\n",
    "\n",
    "# print(f\"\\n最终训练数据规模: {train_df_v6.shape}\")\n",
    "# print(f\"标签分布:\\n{train_df_v6['label'].value_counts()}\")\n",
    "\n",
    "# # 验证去重效果\n",
    "# print(f\"\\n验证去重效果:\")\n",
    "# duplicate_check = train_df_v6.groupby(['congress', 'mid', 'issue']).size()\n",
    "# duplicates = duplicate_check[duplicate_check > 1]\n",
    "# print(f\"重复的(congress, mid, issue)组合数量: {len(duplicates)}\")\n",
    "\n",
    "# # 显示数据结构\n",
    "# print(f\"\\n数据结构预览:\")\n",
    "# print(train_df_v6.head())\n",
    "# print(f\"\\n列名: {list(train_df_v6.columns)}\")\n",
    "\n",
    "\n",
    "# # 保存完整的训练数据\n",
    "# train_df_v6.to_csv(\"./output/cash_data_label.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe60cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_v6 = pd.read_csv(TRAIN_DATA_DIR / \"cash_data_label.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db15e06a",
   "metadata": {},
   "source": [
    "### 2.3 生成所有样本并平衡正负样本比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce80b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 计算需要采样的负样本数量\n",
    "# num_positive_samples = len(positive_samples_df)\n",
    "# num_negative_samples_to_sample = num_positive_samples * 2\n",
    "\n",
    "# # 从负样本中随机采样（有放回）\n",
    "# negative_samples_df = negative_samples_df.sample(n=num_negative_samples_to_sample, random_state=42, replace=True)\n",
    "\n",
    "# # 合并正负样本作为训练集\n",
    "# train_df = pd.concat([negative_samples_df, positive_samples_df])\n",
    "\n",
    "# # # 处理日期和国会届次\n",
    "# # # 格式化日期并转换为datetime类型\n",
    "# train_df[\"date\"] = train_df.apply(lambda x: f'{x[\"cur_year\"]}-{x[\"cur_month\"]:02d}', axis=1)\n",
    "# train_df[\"date\"] = pd.to_datetime(train_df[\"date\"], format='%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7727ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用范围筛选115-118届次的数据\n",
    "train_df = train_df_v6[(train_df_v6['congress'] >= 115) & (train_df_v6['congress'] <= 118)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bad4ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    42879\n",
       "0    25761\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0668398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68640, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bffe27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['mid']=='G000584']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62217b94",
   "metadata": {},
   "source": [
    "## 3. 从PostgreSQL获取议员和委员会数据\n",
    "### 3.1 从数据库获取议员和委员会数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c36db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "    user=os.getenv(\"PG_USER\"),\n",
    "    password=os.getenv(\"PG_PASSWORD\"),\n",
    "    host=os.getenv(\"PG_HOST\"),\n",
    "    port=os.getenv(\"PG_PORT\"),\n",
    "    database=os.getenv(\"PG_DB\")\n",
    ")\n",
    "\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a25a7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取目标议员的唯一标识列表\n",
    "target_mid_list = list(train_df[\"mid\"].unique())\n",
    "\n",
    "# 将列表转换为逗号分隔的字符串，并用单引号包裹每个元素\n",
    "formatted_mid_list = ', '.join(f\"'{mid}'\" for mid in target_mid_list)\n",
    "\n",
    "# 构建查询字符串，直接在 SQL 中处理数据\n",
    "query = f\"\"\"\n",
    "    SELECT \n",
    "        bioguide_id, \n",
    "        full_name, \n",
    "        chamber, \n",
    "        CASE \n",
    "            WHEN birth_year IS NOT NULL THEN 2024 - birth_year \n",
    "            ELSE NULL \n",
    "        END AS age, \n",
    "        party, \n",
    "        state_code, \n",
    "        district, \n",
    "        CASE \n",
    "            WHEN name_info::jsonb ? 'honor_name' THEN name_info::jsonb->>'honor_name' \n",
    "            ELSE NULL \n",
    "        END AS honor,\n",
    "        terms\n",
    "    FROM \n",
    "        members\n",
    "    WHERE \n",
    "        bioguide_id IN ({formatted_mid_list})\n",
    "\"\"\"\n",
    "\n",
    "# 执行查询并获取数据\n",
    "cursor.execute(query)\n",
    "members_data = cursor.fetchall()\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# 从 committees_membership 和 committees 数据库中获取所有数据\n",
    "# 先创建临时表 committees_official，将 committees 中 official_name 匹配到 committees_membership\n",
    "# 然后根据 committees_membership 完成数据查询\n",
    "query_combined = f\"\"\"\n",
    "\n",
    "    WITH committees_official AS(\n",
    "    SELECT \n",
    "\t\tch.thomas_id,\n",
    "\t\tch.thomas_num,\n",
    "\t\tch.congress,\n",
    "\t\tc.official_name\n",
    "    FROM \n",
    "\t\tcommittees_history ch\n",
    "    LEFT JOIN \n",
    "\t\tcommittees c\n",
    "    ON \n",
    "\t\tc.thomas_id = ch.thomas_id AND c.thomas_num = ch.thomas_num    \n",
    "    )\n",
    "    SELECT \n",
    "        cm.member_id, \n",
    "        cm.congress, \n",
    "        cm.thomas_id AS cm_thomas_id, \n",
    "        cm.thomas_num, \n",
    "        cm.title, \n",
    "        co.official_name\n",
    "    FROM \n",
    "        committees_membership cm\n",
    "    LEFT JOIN \n",
    "        committees_official co\n",
    "    ON \n",
    "        cm.thomas_id = co.thomas_id AND cm.thomas_num = co.thomas_num AND cm.congress = co.congress\n",
    "    WHERE\n",
    "        cm.member_id IN ({formatted_mid_list}) AND cm.thomas_num = '00' AND cm.congress >= 115\n",
    "\"\"\"\n",
    "cursor.execute(query_combined)\n",
    "combined_data = cursor.fetchall()\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# 获取选区的数据\n",
    "sql = \"\"\"\n",
    "    SELECT congress, state_code, district, ppvi, npvi, employee, payroll, ethnicity\n",
    "    FROM district\n",
    "    WHERE congress >= 115;\n",
    "\"\"\"\n",
    "cursor.execute(sql)\n",
    "district_data = cursor.fetchall()\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# 获取州的数据\n",
    "sql = \"\"\"\n",
    "    SELECT congress, state_code, ppvi AS state_ppvi, npvi AS state_npvi, employee AS state_employee, payroll AS state_payroll, ethnicity AS state_ethnicity\n",
    "    FROM state\n",
    "    WHERE congress >= 115;\n",
    "\"\"\"\n",
    "cursor.execute(sql)\n",
    "state_data = cursor.fetchall()\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# 构建意识形态的数据\n",
    "sql = f\"\"\"\n",
    "SELECT \n",
    "        cm.member_id, \n",
    "        cm.congress, \n",
    "        cm.thomas_id AS cm_thomas_id, \n",
    "        cm.thomas_num, \n",
    "        co.ideology\n",
    "    FROM \n",
    "        committees_membership cm\n",
    "    LEFT JOIN \n",
    "        committees_analysis co\n",
    "    ON \n",
    "        cm.thomas_id = co.thomas_id AND cm.thomas_num = co.thomas_num AND cm.congress = co.congress\n",
    "    WHERE\n",
    "        cm.member_id IN ({formatted_mid_list}) AND cm.thomas_num = '00' AND cm.congress >= 115\n",
    "\"\"\"\n",
    "cursor.execute(sql)\n",
    "df_ideology = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a38843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关闭数据库连接\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b781773",
   "metadata": {},
   "source": [
    "### 3.2 处理获取的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb4e6061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为 DataFrame\n",
    "columns = [\"bioguide_id\", \"full_name\", \"chamber\", \"age\", \"party\", \"state_code\", \"district\", \"honor\",\"terms\"]\n",
    "df_members = pd.DataFrame(members_data, columns=columns)\n",
    "\n",
    "columns = [\"member_id\", \"congress\", \"cm_thomas_id\", \"thomas_num\", \"title\", \"official_name\"]\n",
    "df_combined = pd.DataFrame(combined_data, columns=columns)\n",
    "\n",
    "columns = [\"congress\", \"state_code\", \"district\", \"ppvi\", \"npvi\", \"employ\", \"payroll\", \"ethnicity\"]\n",
    "df_district = pd.DataFrame(district_data, columns=columns)\n",
    "\n",
    "columns = [\"congress\", \"state_code\", \"state_ppvi\", \"state_npvi\", \"state_employ\", \"state_payroll\", \"state_ethnicity\"]\n",
    "df_state = pd.DataFrame(state_data, columns=columns)\n",
    "\n",
    "columns = [\"member_id\", \"congress\", \"cm_thomas_id\", \"thomas_num\", \"ideology\"]\n",
    "df_ideology = pd.DataFrame(df_ideology, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f982a57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过滤前PVI数据规模: (2970, 5)\n",
      "congress列缺失值数量: 0\n",
      "过滤后选区级PVI数据规模: (2970, 5)\n",
      "包含的congress: [113, 114, 115, 116, 117, 118]\n",
      "\n",
      "=== 格式统一后的匹配键信息 ===\n",
      "df_pvi_sub - congress类型: int32, postal类型: object, district类型: object\n",
      "df_district - congress类型: int32, state_code类型: object, district类型: object\n",
      "更新后df_district的规模: (1748, 8)\n",
      "ppvi缺失值数量: 35\n",
      "npvi缺失值数量: 71\n"
     ]
    }
   ],
   "source": [
    "# 更新PVI的取值\n",
    "# === 用PVI表更新df_district中的ppvi和npvi ===\n",
    "import numpy as np\n",
    "\n",
    "# 读取PVI数据\n",
    "df_pvi = pd.read_excel('./input/pvi-full-new.xlsx', sheet_name='full')\n",
    "# 提取PVI中的字母部分为ppvi，数字部分为npvi\n",
    "df_pvi['ppvi'] = df_pvi['PVI'].str.extract(r'([A-Za-z]+)')\n",
    "df_pvi['npvi'] = df_pvi['PVI'].str.extract(r'(\\d+)')\n",
    "\n",
    "# 2. 仅保留df_pvi中用于匹配和更新的必要列，使用copy()避免警告\n",
    "df_pvi_sub = df_pvi[['congress', 'postal', 'district', 'ppvi', 'npvi']].copy()\n",
    "\n",
    "# === 过滤掉congress为NaN的数据 ===\n",
    "print(f\"过滤前PVI数据规模: {df_pvi_sub.shape}\")\n",
    "print(f\"congress列缺失值数量: {df_pvi_sub['congress'].isna().sum()}\")\n",
    "\n",
    "# 删除congress为NaN的行\n",
    "df_pvi_sub = df_pvi_sub.dropna(subset=['congress'])\n",
    "\n",
    "print(f\"过滤后选区级PVI数据规模: {df_pvi_sub.shape}\")\n",
    "print(f\"包含的congress: {sorted(df_pvi_sub['congress'].unique())}\")\n",
    "\n",
    "# === 统一字符格式，处理匹配键 ===\n",
    "# 1. 统一congress列的数据类型\n",
    "df_pvi_sub['congress'] = df_pvi_sub['congress'].astype(int)\n",
    "df_district['congress'] = df_district['congress'].astype(int)\n",
    "\n",
    "# 2. 统一州代码格式：去除空格，转为大写\n",
    "df_pvi_sub['postal'] = df_pvi_sub['postal'].astype(str).str.strip().str.upper()\n",
    "df_district['state_code'] = df_district['state_code'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# 3. 统一district格式：转为字符串，去除空格\n",
    "df_pvi_sub['district'] = df_pvi_sub['district'].astype(str).str.strip()\n",
    "df_district['district'] = df_district['district'].astype(str).str.strip()\n",
    "\n",
    "# 输出格式统一后的匹配键信息\n",
    "print(f\"\\n=== 格式统一后的匹配键信息 ===\")\n",
    "print(f\"df_pvi_sub - congress类型: {df_pvi_sub['congress'].dtype}, postal类型: {df_pvi_sub['postal'].dtype}, district类型: {df_pvi_sub['district'].dtype}\")\n",
    "print(f\"df_district - congress类型: {df_district['congress'].dtype}, state_code类型: {df_district['state_code'].dtype}, district类型: {df_district['district'].dtype}\")\n",
    "\n",
    "# 1. 先将df_district中的ppvi和npvi设为NaN，方便后续整体替换\n",
    "df_district = df_district.copy()  # 创建副本避免警告\n",
    "df_district['ppvi'] = np.nan\n",
    "df_district['npvi'] = np.nan\n",
    "\n",
    "# 3. 按congress、state_code/postal、district三列合并，获取最新ppvi和npvi\n",
    "df_district = df_district.merge(\n",
    "    df_pvi_sub,\n",
    "    left_on=['congress', 'state_code', 'district'],\n",
    "    right_on=['congress', 'postal', 'district'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# 4. 用合并后的新ppvi和npvi覆盖原有值\n",
    "df_district['ppvi'] = df_district['ppvi_new']\n",
    "df_district['npvi'] = df_district['npvi_new']\n",
    "\n",
    "# 5. 删除合并产生的多余列\n",
    "df_district = df_district.drop(columns=['ppvi_new', 'npvi_new', 'postal'])\n",
    "\n",
    "print(f\"更新后df_district的规模: {df_district.shape}\")\n",
    "print(f\"ppvi缺失值数量: {df_district['ppvi'].isna().sum()}\")\n",
    "print(f\"npvi缺失值数量: {df_district['npvi'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffef50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已添加115届数据\n",
      "添加后规模: 208\n",
      "各届次分布:\n",
      "congress\n",
      "115    52\n",
      "116    52\n",
      "117    52\n",
      "118    52\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 获取所有唯一的state_code\n",
    "unique_state_codes = df_state['state_code'].unique()\n",
    "\n",
    "# 检查是否已经存在115届数据，避免重复添加\n",
    "if 115 not in df_state['congress'].values:\n",
    "    # 为115届创建空数据行\n",
    "    df_115_rows = []\n",
    "    for state_code in unique_state_codes:\n",
    "        df_115_rows.append({'congress': 115, 'state_code': state_code})\n",
    "    \n",
    "    # 转为DataFrame并合并\n",
    "    df_115 = pd.DataFrame(df_115_rows)\n",
    "    df_state = pd.concat([df_state, df_115], ignore_index=True)\n",
    "    print(f\"已添加115届数据\")\n",
    "else:\n",
    "    print(f\"115届数据已存在，跳过添加\")\n",
    "\n",
    "print(f\"添加后规模: {len(df_state)}\")\n",
    "print(f\"各届次分布:\\n{df_state['congress'].value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26471a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "州级PVI数据规模: (336, 4)\n",
      "包含的congress: [113, 114, 115, 116, 117, 118]\n",
      "更新后df_state的规模: (208, 7)\n",
      "state_ppvi缺失值数量: 4\n",
      "state_npvi缺失值数量: 12\n"
     ]
    }
   ],
   "source": [
    "# 州级PVI数据更新\n",
    "df_pvi_state = pd.read_excel('./input/pvi-full-new.xlsx', sheet_name='full')\n",
    "\n",
    "df_pvi_state['ppvi'] = df_pvi_state['PVI'].str.extract(r'([A-Za-z]+)')\n",
    "df_pvi_state['npvi'] = df_pvi_state['PVI'].str.extract(r'(\\d+)')\n",
    "\n",
    "# 筛选district为'99'的数据作为州级数据\n",
    "df_pvi_state_sub = df_pvi_state[df_pvi_state['district'] == 99][['congress', 'postal', 'ppvi', 'npvi']]\n",
    "\n",
    "print(f\"州级PVI数据规模: {df_pvi_state_sub.shape}\")\n",
    "print(f\"包含的congress: {sorted(df_pvi_state_sub['congress'].unique())}\")\n",
    "\n",
    "# 1. 先将df_state中的state_ppvi和state_npvi设为NaN，方便后续整体替换\n",
    "df_state['state_ppvi'] = np.nan\n",
    "df_state['state_npvi'] = np.nan\n",
    "\n",
    "# 2. 按congress、state_code/postal两列合并，获取最新的州级ppvi和npvi\n",
    "df_state = df_state.merge(\n",
    "    df_pvi_state_sub,\n",
    "    left_on=['congress', 'state_code'],\n",
    "    right_on=['congress', 'postal'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# 3. 用合并后的新ppvi和npvi覆盖原有的state_ppvi和state_npvi值\n",
    "df_state['state_ppvi'] = df_state['ppvi']\n",
    "df_state['state_npvi'] = df_state['npvi']\n",
    "\n",
    "# 4. 删除合并产生的多余列\n",
    "df_state = df_state.drop(columns=['ppvi', 'npvi', 'postal'])\n",
    "\n",
    "print(f\"更新后df_state的规模: {df_state.shape}\")\n",
    "print(f\"state_ppvi缺失值数量: {df_state['state_ppvi'].isna().sum()}\")\n",
    "print(f\"state_npvi缺失值数量: {df_state['state_npvi'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bda7f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "填充前Senate缺失district数: 138\n",
      "填充前House缺失district数: 16\n",
      "填充后district列总缺失数: 0\n"
     ]
    }
   ],
   "source": [
    "# 填充df_member缺失的district值\n",
    "# 对于Senate成员，将district设为'99'\n",
    "# 对于House成员，将district设为'At Large'\n",
    "\n",
    "# 创建填充条件\n",
    "senate_mask = (df_members['district'].isna()) & (df_members['chamber'] == 'Senate')\n",
    "house_mask = (df_members['district'].isna()) & (df_members['chamber'] == 'House of Representatives')\n",
    "\n",
    "# 打印填充前的统计\n",
    "print(f\"填充前Senate缺失district数: {senate_mask.sum()}\")\n",
    "print(f\"填充前House缺失district数: {house_mask.sum()}\")\n",
    "\n",
    "# 根据条件填充值\n",
    "# df_members.loc[senate_mask, 'district'] = 'At Large'\n",
    "# df_members.loc[house_mask, 'district'] = '99'\n",
    "\n",
    "df_members.loc[senate_mask, 'district'] = '99'\n",
    "df_members.loc[house_mask, 'district'] = 'At Large'\n",
    "\n",
    "\n",
    "# 打印填充后的统计\n",
    "print(f\"填充后district列总缺失数: {df_members['district'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "281b10b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并df_ideology中的ideology列到df_combined中\n",
    "df_combined = df_combined.merge(\n",
    "    df_ideology[['member_id', 'congress', 'cm_thomas_id', 'thomas_num', 'ideology']],\n",
    "    on=['member_id', 'congress', 'cm_thomas_id', 'thomas_num'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "050edf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据议员称呼确定性别 (Mr. 为男性，其他为女性)\n",
    "df_members[\"gender\"] = df_members[\"honor\"].apply(lambda x: 1 if x == \"Mr.\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f176e",
   "metadata": {},
   "source": [
    "### 3.3 合并基础特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1945f804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并议员信息后的数据规模: (68640, 15)\n"
     ]
    }
   ],
   "source": [
    "# 合并议员信息\n",
    "train_df = train_df.merge(\n",
    "    df_members, \n",
    "    left_on=[\"mid\"], \n",
    "    right_on=[\"bioguide_id\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"合并议员信息后的数据规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4682f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['district'] == '99'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b2361a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_beifen = train_df.copy()\n",
    "train_df = train_df_beifen.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad361f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      congress district\n",
       "1147       118        2\n",
       "1672       117        2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['mid'] == 'R000103'][['congress','district']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae4ede41",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['district'] = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bc198f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 更新前统计 ===\n",
      "train_df规模: (68640, 15)\n",
      "df_members_district规模: (2221, 5)\n",
      "train_df中district缺失值数量: 0\n",
      "\n",
      "=== 数据类型检查 ===\n",
      "train_df - mid类型: object, congress类型: int64\n",
      "df_members_district - bioguide_id类型: object, congress类型: int64\n",
      "train_df - district类型: int64\n",
      "df_members_district - district类型: float64\n",
      "处理后df_members_district规模: (2219, 5)\n",
      "删除了 2 行特定议员的district为空数据\n",
      "\n",
      "=== 更新后统计 ===\n",
      "更新后train_df规模: (68640, 15)\n",
      "更新后district缺失值数量: 0\n",
      "更新后district数据类型: object\n",
      "成功匹配的记录数: 2145\n",
      "\n",
      "=== District值样例检查 ===\n",
      "District唯一值示例: ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18']\n"
     ]
    }
   ],
   "source": [
    "# 选区数据更新\n",
    "df_members_district_origin = pd.read_csv('./input/议员选区数据.csv')\n",
    "\n",
    "# 筛选出115-118届次的数据\n",
    "df_members_district = df_members_district_origin[(df_members_district_origin['congress'] >= 115) & (df_members_district_origin['congress'] <= 118)]\n",
    "\n",
    "# 使用df_members_district更新train_df中的district数据\n",
    "print(f\"=== 更新前统计 ===\")\n",
    "print(f\"train_df规模: {train_df.shape}\")\n",
    "print(f\"df_members_district规模: {df_members_district.shape}\")\n",
    "print(f\"train_df中district缺失值数量: {train_df['district'].isna().sum()}\")\n",
    "\n",
    "# 检查匹配键的数据类型和格式\n",
    "print(f\"\\n=== 数据类型检查 ===\")\n",
    "print(f\"train_df - mid类型: {train_df['mid'].dtype}, congress类型: {train_df['congress'].dtype}\")\n",
    "print(f\"df_members_district - bioguide_id类型: {df_members_district['bioguide_id'].dtype}, congress类型: {df_members_district['congress'].dtype}\")\n",
    "print(f\"train_df - district类型: {train_df['district'].dtype}\")\n",
    "print(f\"df_members_district - district类型: {df_members_district['district'].dtype}\")\n",
    "\n",
    "# 统一数据类型\n",
    "train_df['congress'] = train_df['congress'].astype(int)\n",
    "df_members_district['congress'] = df_members_district['congress'].astype(int)\n",
    "\n",
    "# # 特别处理df_members_district的district列：先转为整数再转为字符串，避免小数点\n",
    "# # 对于float类型的district，先填充NaN，然后转为int再转为str\n",
    "df_members_district['district'] = df_members_district['district'].fillna(-999)  # 临时填充\n",
    "df_members_district['district'] = df_members_district['district'].astype(int)\n",
    "df_members_district['district'] = df_members_district['district'].astype(str)\n",
    "df_members_district['district'] = df_members_district['district'].replace('-999', pd.NA)  # 恢复NaN\n",
    "\n",
    "# 更新前清空\n",
    "train_df['district'] = 99999\n",
    "\n",
    "# 统一train_df的district列数据类型为字符串\n",
    "train_df['district'] = train_df['district'].astype(str)\n",
    "\n",
    "\n",
    "# 处理可能的空值，将字符串'nan'转换为pandas的NA\n",
    "train_df['district'] = train_df['district'].replace('nan', pd.NA)\n",
    "df_members_district['district'] = df_members_district['district'].replace('nan', pd.NA)\n",
    "\n",
    "# 创建筛选条件：删除K000394和S001150议员中district为空的数据\n",
    "condition_to_remove = (\n",
    "    df_members_district['bioguide_id'].isin(['K000394', 'S001150']) & \n",
    "    (df_members_district['district'].isna() | \n",
    "     (df_members_district['district'] == '') | \n",
    "     (df_members_district['district'] == 'nan'))\n",
    ")\n",
    "\n",
    "# 保留不满足删除条件的数据\n",
    "df_members_district = df_members_district[~condition_to_remove]\n",
    "print(f\"处理后df_members_district规模: {df_members_district.shape}\")\n",
    "print(f\"删除了 {condition_to_remove.sum()} 行特定议员的district为空数据\")\n",
    "\n",
    "\n",
    "\n",
    "# 执行左连接合并，更新district信息\n",
    "train_df_updated = train_df.merge(\n",
    "    df_members_district[['bioguide_id', 'congress', 'district']],\n",
    "    left_on=['mid', 'congress'],\n",
    "    right_on=['bioguide_id', 'congress'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# 用新的district值覆盖原有值（优先使用df_members_district中的数据）\n",
    "# 如果df_members_district中有匹配的数据，就使用新值；否则保持原值\n",
    "train_df_updated['district'] = train_df_updated['district_new'].fillna(train_df_updated['district'])\n",
    "\n",
    "# 确保最终的district列保持字符串类型\n",
    "train_df_updated['district'] = train_df_updated['district'].astype(str)\n",
    "\n",
    "# 再次处理可能出现的'nan'字符串\n",
    "train_df_updated['district'] = train_df_updated['district'].replace('nan', pd.NA)\n",
    "\n",
    "# 删除合并产生的多余列\n",
    "train_df_updated = train_df_updated.drop(columns=['district_new', 'bioguide_id'])\n",
    "\n",
    "# 更新原始的train_df\n",
    "train_df = train_df_updated\n",
    "\n",
    "print(f\"\\n=== 更新后统计 ===\")\n",
    "print(f\"更新后train_df规模: {train_df.shape}\")\n",
    "print(f\"更新后district缺失值数量: {train_df['district'].isna().sum()}\")\n",
    "print(f\"更新后district数据类型: {train_df['district'].dtype}\")\n",
    "\n",
    "# 统计匹配效果\n",
    "matched_count = len(df_members_district.merge(\n",
    "    train_df[['mid', 'congress']].drop_duplicates(),\n",
    "    left_on=['bioguide_id', 'congress'],\n",
    "    right_on=['mid', 'congress'],\n",
    "    how='inner'\n",
    "))\n",
    "\n",
    "print(f\"成功匹配的记录数: {matched_count}\")\n",
    "\n",
    "# 检查district值的样例，确认没有小数点\n",
    "print(f\"\\n=== District值样例检查 ===\")\n",
    "print(f\"District唯一值示例: {sorted(train_df['district'].dropna().unique())[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfff7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['mid'] == 'R000103'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef15dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['district']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed0ff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "填充前Senate缺失district数: 13024\n",
      "填充前House缺失district数: 1280\n",
      "填充后district列总缺失数: 0\n"
     ]
    }
   ],
   "source": [
    "# 填充df_member缺失的district值\n",
    "# 对于Senate成员，将district设为'99'\n",
    "# 对于House成员，将district设为'At Large'\n",
    "\n",
    "# 创建填充条件\n",
    "senate_mask = (train_df['district'] == '99999') & (train_df['chamber'] == 'Senate')\n",
    "house_mask = (train_df['district'] == '99999') & (train_df['chamber'] == 'House of Representatives')\n",
    "\n",
    "# 打印填充前的统计\n",
    "print(f\"填充前Senate缺失district数: {senate_mask.sum()}\")\n",
    "print(f\"填充前House缺失district数: {house_mask.sum()}\")\n",
    "\n",
    "# 根据条件填充值\n",
    "# train_df.loc[senate_mask, 'district'] = 'At Large'\n",
    "# train_df.loc[house_mask, 'district'] = '99'\n",
    "\n",
    "train_df.loc[senate_mask, 'district'] = '99'\n",
    "train_df.loc[house_mask, 'district'] = 'At Large'\n",
    "\n",
    "# 打印填充后的统计\n",
    "print(f\"填充后district列总缺失数: {train_df['district'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba317196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>issue</th>\n",
       "      <th>mid</th>\n",
       "      <th>label</th>\n",
       "      <th>date</th>\n",
       "      <th>full_name</th>\n",
       "      <th>chamber</th>\n",
       "      <th>age</th>\n",
       "      <th>party</th>\n",
       "      <th>state_code</th>\n",
       "      <th>district</th>\n",
       "      <th>honor</th>\n",
       "      <th>terms</th>\n",
       "      <th>gender</th>\n",
       "      <th>bioguide_id_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>118</td>\n",
       "      <td>social welfare</td>\n",
       "      <td>T000474</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"count\": 1, \"dates\": [{\"year\": 2023, \"month\":...</td>\n",
       "      <td>Rep. Torres, Norma J. [D-CA-35]</td>\n",
       "      <td>House of Representatives</td>\n",
       "      <td>59</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>CA</td>\n",
       "      <td>35</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>[{'chamber': 'House of Representatives', 'endY...</td>\n",
       "      <td>0</td>\n",
       "      <td>T000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>115</td>\n",
       "      <td>international finance</td>\n",
       "      <td>T000474</td>\n",
       "      <td>0</td>\n",
       "      <td>{\"count\": 0, \"dates\": [], \"first_date\": null, ...</td>\n",
       "      <td>Rep. Torres, Norma J. [D-CA-35]</td>\n",
       "      <td>House of Representatives</td>\n",
       "      <td>59</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>CA</td>\n",
       "      <td>35</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>[{'chamber': 'House of Representatives', 'endY...</td>\n",
       "      <td>0</td>\n",
       "      <td>T000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>118</td>\n",
       "      <td>health</td>\n",
       "      <td>C001131</td>\n",
       "      <td>1</td>\n",
       "      <td>{\"count\": 2, \"dates\": [{\"year\": 2024, \"month\":...</td>\n",
       "      <td>Rep. Casar, Greg [D-TX-35]</td>\n",
       "      <td>House of Representatives</td>\n",
       "      <td>35</td>\n",
       "      <td>Democratic</td>\n",
       "      <td>TX</td>\n",
       "      <td>35</td>\n",
       "      <td>Mr.</td>\n",
       "      <td>[{'chamber': 'House of Representatives', 'endY...</td>\n",
       "      <td>1</td>\n",
       "      <td>C001131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     congress                  issue      mid  label  \\\n",
       "223       118         social welfare  T000474      1   \n",
       "392       115  international finance  T000474      0   \n",
       "534       118                 health  C001131      1   \n",
       "\n",
       "                                                  date  \\\n",
       "223  {\"count\": 1, \"dates\": [{\"year\": 2023, \"month\":...   \n",
       "392  {\"count\": 0, \"dates\": [], \"first_date\": null, ...   \n",
       "534  {\"count\": 2, \"dates\": [{\"year\": 2024, \"month\":...   \n",
       "\n",
       "                           full_name                   chamber  age  \\\n",
       "223  Rep. Torres, Norma J. [D-CA-35]  House of Representatives   59   \n",
       "392  Rep. Torres, Norma J. [D-CA-35]  House of Representatives   59   \n",
       "534       Rep. Casar, Greg [D-TX-35]  House of Representatives   35   \n",
       "\n",
       "          party state_code district honor  \\\n",
       "223  Democratic         CA       35  Mrs.   \n",
       "392  Democratic         CA       35  Mrs.   \n",
       "534  Democratic         TX       35   Mr.   \n",
       "\n",
       "                                                 terms  gender bioguide_id_new  \n",
       "223  [{'chamber': 'House of Representatives', 'endY...       0         T000474  \n",
       "392  [{'chamber': 'House of Representatives', 'endY...       0         T000474  \n",
       "534  [{'chamber': 'House of Representatives', 'endY...       1         C001131  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['district'] == '35'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4c361ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\n",
    "# (train_df['full_name'] == 'Rep. Doggett, Lloyd [D-TX-37]') &\n",
    "#     (train_df['congress'] == 118)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cffd1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 修正后的查询条件\n",
    "# train_df[\n",
    "# (train_df['congress'] == 117) &\n",
    "# (train_df['state_code'] == 'TX') & \n",
    "# (train_df['district'] == 35)  # 将数字35改为字符串'35'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31669e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_seniority(terms_data, current_congress):\n",
    "    \"\"\"\n",
    "    计算议员的资历(seniority)，基于terms列表中的任期信息\n",
    "    只计算严格小于current_congress的任期（不含当前届次）\n",
    "    \n",
    "    参数:\n",
    "    terms_data: JSON字符串或Python对象(列表/字典)\n",
    "    current_congress: 当前国会届次，只计算此届次之前的资历\n",
    "    \n",
    "    返回:\n",
    "    整数: 议员截止当前届次前的总在任年数\n",
    "    \"\"\"\n",
    "    import json\n",
    "    \n",
    "    # 如果terms_data是字符串，尝试解析为Python对象\n",
    "    if isinstance(terms_data, str):\n",
    "        try:\n",
    "            terms_list = json.loads(terms_data)\n",
    "        except json.JSONDecodeError:\n",
    "            return 0  # 返回0，表示无法解析\n",
    "    else:\n",
    "        terms_list = terms_data\n",
    "    \n",
    "    # 确保terms_list是一个列表\n",
    "    if not isinstance(terms_list, list):\n",
    "        return 0\n",
    "    \n",
    "    # 计算总在任时间\n",
    "    total_years = 0\n",
    "    for term in terms_list:\n",
    "        term_congress = term.get('congress')\n",
    "        \n",
    "        # 跳过未来的任期或大于等于当前国会届次的任期\n",
    "        if term_congress is None or term_congress >= current_congress:\n",
    "            continue\n",
    "            \n",
    "        # 计算当前任期的年数\n",
    "        start_year = term.get('startYear')\n",
    "        end_year = term.get('endYear')\n",
    "        \n",
    "        # 确保startYear和endYear都存在且为数字\n",
    "        if isinstance(start_year, (int, float)) and isinstance(end_year, (int, float)):\n",
    "            term_duration = end_year - start_year\n",
    "            total_years += term_duration\n",
    "            \n",
    "    return total_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb110a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用函数到train_df，根据每行的congress计算相应的资历\n",
    "train_df['seniority'] = train_df.apply(\n",
    "    lambda row: calculate_seniority(row['terms'], row['congress']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# # 查看结果\n",
    "# print(\"添加资历特征后:\")\n",
    "# print(train_df[['mid', 'congress', 'seniority']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f1c3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 议员对应委员会去重，会出现一个议员同一届加入了多届委员会的情况；\n",
    "# 优先使用有 Title 的委员会，没有则取第一个委员会\n",
    "df_combined.drop_duplicates(subset=[\"member_id\", \"congress\"])\n",
    "\n",
    "def filter_committees(df):\n",
    "    filtered_rows = []\n",
    "    grouped = df.groupby(['member_id', 'congress'])\n",
    "\n",
    "    for name, group in grouped:\n",
    "        if group['title'].notna().any():\n",
    "            filtered_row = group[group['title'].notna()].iloc[0]\n",
    "        else:\n",
    "            filtered_row = group.iloc[0]\n",
    "        filtered_rows.append(filtered_row)\n",
    "\n",
    "    return pd.DataFrame(filtered_rows)\n",
    "\n",
    "df_combined = filter_committees(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8309199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并委员会信息后的数据规模: (68640, 22)\n"
     ]
    }
   ],
   "source": [
    "# 合并委员会信息\n",
    "train_df = train_df.merge(\n",
    "    df_combined,\n",
    "    left_on=[\"mid\", \"congress\"],\n",
    "    right_on=[\"member_id\", \"congress\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 重命名相关列\n",
    "train_df = train_df.rename(columns={\n",
    "    \"official_name\": \"committee_el\",\n",
    "    \"title\": \"com_post\"\n",
    "})\n",
    "print(f\"合并委员会信息后的数据规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1a63f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 展开特征列表的函数\n",
    "# def expand_list_column(df, column_name):\n",
    "#     \"\"\"将列表类型的列展开为多个列\"\"\"\n",
    "#     expanded_df = pd.DataFrame(df[column_name].tolist(), index=df.index)\n",
    "#     expanded_df.columns = [f\"{column_name}{i + 1}\" for i in range(expanded_df.shape[1])]\n",
    "#     return expanded_df\n",
    "\n",
    "\n",
    "# 展开特征列表的函数（改进版）\n",
    "def expand_list_column(df, column_name):\n",
    "    \"\"\"将列表类型的列展开为多个列，处理空值情况\"\"\"\n",
    "    # 处理空值，将NaN替换为空列表\n",
    "    column_data = df[column_name].fillna('').apply(lambda x: x if isinstance(x, list) else [])\n",
    "    \n",
    "    # 如果所有值都是空列表，创建一个包含单列的DataFrame\n",
    "    if all(len(item) == 0 for item in column_data):\n",
    "        expanded_df = pd.DataFrame({f\"{column_name}1\": [None] * len(df)}, index=df.index)\n",
    "    else:\n",
    "        # 找出最大长度\n",
    "        max_length = max(len(item) for item in column_data if len(item) > 0)\n",
    "        # 将所有列表填充到相同长度\n",
    "        padded_data = [item + [None] * (max_length - len(item)) for item in column_data]\n",
    "        expanded_df = pd.DataFrame(padded_data, index=df.index)\n",
    "        expanded_df.columns = [f\"{column_name}{i + 1}\" for i in range(expanded_df.shape[1])]\n",
    "    \n",
    "    return expanded_df\n",
    "\n",
    "\n",
    "# 扩展 district 中的 employ, payroll, and ethnicity 列\n",
    "employ_expanded = expand_list_column(df_district, \"employ\")\n",
    "payroll_expanded = expand_list_column(df_district, \"payroll\")\n",
    "ethnicity_expanded = expand_list_column(df_district, \"ethnicity\")\n",
    "\n",
    "df_district_expanded = pd.concat([\n",
    "    df_district.drop(columns=[\"employ\", \"payroll\", \"ethnicity\"]), \n",
    "    employ_expanded, \n",
    "    payroll_expanded, \n",
    "    ethnicity_expanded\n",
    "], axis=1)\n",
    "\n",
    "# 扩展 state 中的 employ, payroll, and ethnicity 列\n",
    "state_employ_expanded = expand_list_column(df_state, \"state_employ\")\n",
    "state_payroll_expanded = expand_list_column(df_state, \"state_payroll\")\n",
    "state_ethnicity_expanded = expand_list_column(df_state, \"state_ethnicity\")\n",
    "\n",
    "df_state_expanded = pd.concat([\n",
    "    df_state.drop(columns=[\"state_employ\", \"state_payroll\", \"state_ethnicity\"]),\n",
    "    state_employ_expanded,\n",
    "    state_payroll_expanded,\n",
    "    state_ethnicity_expanded\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "778e44e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从本地加载115届州数据，合并到现有的数据中\n",
    "df_state_115 = pd.read_csv(DATA_DIR / 'state_115_1220_with_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce77a5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并前df_state_expanded规模: (208, 13)\n",
      "df_state_115_for_merge规模: (52, 11)\n",
      "合并后df_state_expanded规模: (208, 13)\n"
     ]
    }
   ],
   "source": [
    "# 准备df_state_115的数据，重命名列以匹配目标格式\n",
    "df_state_115_prepared = df_state_115.copy()\n",
    "\n",
    "# 重命名列以匹配df_state_expanded的命名规则\n",
    "df_state_115_prepared = df_state_115_prepared.rename(columns={\n",
    "    'Congress': 'congress',  # 统一congress列名\n",
    "    'employ1': 'state_employ1',\n",
    "    'employ2': 'state_employ2', \n",
    "    'employ3': 'state_employ3',\n",
    "    'payroll1': 'state_payroll1',\n",
    "    'payroll2': 'state_payroll2',\n",
    "    'payroll3': 'state_payroll3',\n",
    "    'ethnicity1': 'state_ethnicity1',\n",
    "    'ethinicity2': 'state_ethnicity2', \n",
    "    'ethinicity3': 'state_ethnicity3'  \n",
    "})\n",
    "\n",
    "# 只保留需要合并的列\n",
    "merge_columns = ['congress', 'state_code', 'state_employ1', 'state_employ2', 'state_employ3',\n",
    "                'state_payroll1', 'state_payroll2', 'state_payroll3', \n",
    "                'state_ethnicity1', 'state_ethnicity2', 'state_ethnicity3']\n",
    "\n",
    "df_state_115_for_merge = df_state_115_prepared[merge_columns]\n",
    "\n",
    "# 统一数据类型\n",
    "df_state_115_for_merge['congress'] = df_state_115_for_merge['congress'].astype(int)\n",
    "df_state_expanded['congress'] = df_state_expanded['congress'].astype(int)\n",
    "\n",
    "# 统一字符串格式\n",
    "df_state_115_for_merge['state_code'] = df_state_115_for_merge['state_code'].astype(str).str.strip().str.upper()\n",
    "df_state_expanded['state_code'] = df_state_expanded['state_code'].astype(str).str.strip().str.upper()\n",
    "\n",
    "print(f\"合并前df_state_expanded规模: {df_state_expanded.shape}\")\n",
    "print(f\"df_state_115_for_merge规模: {df_state_115_for_merge.shape}\")\n",
    "\n",
    "# 执行左连接合并\n",
    "df_state_expanded = df_state_expanded.merge(\n",
    "    df_state_115_for_merge,\n",
    "    on=['congress', 'state_code'],\n",
    "    how='left',\n",
    "    suffixes=('', '_115')\n",
    ")\n",
    "\n",
    "# 用df_state_115的数据填充df_state_expanded中的空值\n",
    "target_columns = ['state_employ1', 'state_employ2', 'state_employ3',\n",
    "                 'state_payroll1', 'state_payroll2', 'state_payroll3', \n",
    "                 'state_ethnicity1', 'state_ethnicity2', 'state_ethnicity3']\n",
    "\n",
    "for col in target_columns:\n",
    "    col_115 = col + '_115'\n",
    "    if col_115 in df_state_expanded.columns:\n",
    "        # 用115数据填充空值\n",
    "        df_state_expanded[col] = df_state_expanded[col].fillna(df_state_expanded[col_115])\n",
    "        # 删除临时列\n",
    "        df_state_expanded = df_state_expanded.drop(columns=[col_115])\n",
    "\n",
    "print(f\"合并后df_state_expanded规模: {df_state_expanded.shape}\")\n",
    "\n",
    "# # 检查合并效果\n",
    "# for col in target_columns:\n",
    "#     missing_count = df_state_expanded[col].isna().sum()\n",
    "#     print(f\"{col}缺失值数量: {missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dac3acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68640, 33)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并选区数据\n",
    "train_df = train_df.merge(\n",
    "    df_district_expanded, \n",
    "    on=[\"congress\", \"state_code\", \"district\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae139909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68640, 44)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并州的数据\n",
    "train_df = train_df.merge(\n",
    "    df_state_expanded, \n",
    "    on=[\"congress\", \"state_code\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cea76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_district_expanded[\n",
    "# (df_district_expanded['congress'] == 117) &\n",
    "# (df_district_expanded['state_code'] == 'TX') &\n",
    "# (df_district_expanded['district'] == '35')\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65c4b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 修正后的查询条件\n",
    "# train_df[\n",
    "# (train_df['congress'] == 117) &\n",
    "# (train_df['state_code'] == 'TX') & \n",
    "# (train_df['district'] == \"35\")  \n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0463f08f",
   "metadata": {},
   "source": [
    "对district取值为At Large和99的数据使用州层面的数据进行填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d11556fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "对Senate成员数据总共填充了 142688 个空值\n",
      "\n",
      "\n",
      "对district=99的数据总共填充了 0 个空值\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fill_with_state_data_mask(df, mask, \n",
    "                             columns=['ppvi', 'npvi', 'employ1', 'employ2', 'employ3', \n",
    "                                      'payroll1', 'payroll2', 'payroll3',\n",
    "                                      'ethnicity1', 'ethnicity2', 'ethnicity3'],\n",
    "                             print_detail=True, label=\"\"):\n",
    "    \"\"\"\n",
    "    对满足mask的行，用state_xxx列批量填充columns列的空值。\n",
    "    在原df上直接修改并返回。\n",
    "    \"\"\"\n",
    "    null_before = df.loc[mask, columns].isna().sum()\n",
    "\n",
    "    for col in columns:\n",
    "        state_col = 'state_' + col\n",
    "        if state_col in df.columns:\n",
    "            df.loc[mask, col] = df.loc[mask, state_col]\n",
    "    \n",
    "    null_after = df.loc[mask, columns].isna().sum()\n",
    "    filled = null_before.sum() - null_after.sum()\n",
    "    if print_detail:\n",
    "        print(f\"\\n对{label}总共填充了 {filled} 个空值\\n\")\n",
    "    return df\n",
    "\n",
    "# 用法：\n",
    "senate_mask = train_df['chamber'] == 'Senate'\n",
    "train_df = fill_with_state_data_mask(train_df, mask=senate_mask, label=\"Senate成员数据\")\n",
    "district_99_mask = train_df['district'] == '99'\n",
    "train_df = fill_with_state_data_mask(train_df, mask=district_99_mask, label=\"district=99的数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "135da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['mid'] == 'R000103']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace2c8c7",
   "metadata": {},
   "source": [
    "### 检查缺失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "027309ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chamber                 \n",
       "House of Representatives    480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_view = train_df[train_df['payroll1'].isna()]\n",
    "train_df_view[['chamber']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4b1d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[(train_df['mid']=='B001299') &\n",
    "#          (train_df['congress']==117)  &\n",
    "#          (train_df['cur_month']==2)  ].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1885ce",
   "metadata": {},
   "source": [
    "## 4. 从本地文件加载其他特征\n",
    "### 4.1 准备议题标识符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9df9ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建小写版本的议题名称列，用于后续合并\n",
    "train_df[\"issue_lower\"] = train_df[\"issue\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09949e5a",
   "metadata": {},
   "source": [
    "### 4.2 加载本地数据\n",
    "- 政党议题偏好\n",
    "- 国际压力值\n",
    "- 产业卷入度数据\n",
    "- 这一步才有的party_tp变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75291747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_issue = pd.read_excel(DATA_DIR / \"issue-full_new.xlsx\", sheet_name=\"Sheet1\")\n",
    "df_issue['issue'] = df_issue[\"issue\"].apply(lambda x:x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d18c7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(\n",
    "    df_issue, \n",
    "    left_on=['issue_lower','congress'], \n",
    "    right_on=['issue','congress'], \n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# # 删除不需要的重复列\n",
    "if 'issue_y' in train_df.columns:\n",
    "    train_df = train_df.drop(columns=['issue_y'])\n",
    "\n",
    "# 将issue_x重命名为issue\n",
    "if 'issue_x' in train_df.columns:\n",
    "    train_df = train_df.rename(columns={'issue_x': 'issue'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3e8eb585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['congress', 'issue', 'mid', 'label', 'date', 'full_name', 'chamber',\n",
       "       'age', 'party', 'state_code', 'district', 'honor', 'terms', 'gender',\n",
       "       'bioguide_id_new', 'seniority', 'member_id', 'cm_thomas_id',\n",
       "       'thomas_num', 'com_post', 'committee_el', 'ideology', 'ppvi', 'npvi',\n",
       "       'employ1', 'employ2', 'employ3', 'payroll1', 'payroll2', 'payroll3',\n",
       "       'ethnicity1', 'ethnicity2', 'ethnicity3', 'state_ppvi', 'state_npvi',\n",
       "       'state_employ1', 'state_employ2', 'state_employ3', 'state_payroll1',\n",
       "       'state_payroll2', 'state_payroll3', 'state_ethnicity1',\n",
       "       'state_ethnicity2', 'state_ethnicity3', 'issue_lower', 'issue_ch',\n",
       "       'h_committee_tp1', 'h_committee_tp2', 'h_committee_tp3',\n",
       "       's_committee_tp1', 's_committee_tp2', 's_committee_tp3',\n",
       "       'party_tp_type', 'party_tp_score', 'party_tp', 'industry_tp1',\n",
       "       'industry_tp2', 'industry_tp3', 'ethnicity_tp1', 'ethnicity_tp2',\n",
       "       'ethnicity_tp3', '国际压力值'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f4ce9",
   "metadata": {},
   "source": [
    "### 4.2 加载政党议题偏好数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ccd12e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# party_tp_pd = pd.read_excel(\"./input/议题政党偏好.xlsx\", sheet_name=\"Sheet1\")\n",
    "# party_tp_pd[\"英文名称\"] = party_tp_pd[\"英文名称\"].apply(lambda x:x.lower())\n",
    "# party_tp_melted = party_tp_pd.melt(\n",
    "#     id_vars=[\"英文名称\", \"参议院委员会\", \"众议院委员会\"], \n",
    "#     var_name=\"congress\", \n",
    "#     value_name=\"party_tp\"\n",
    "# )\n",
    "# party_tp_melted[['party_tp_value', 'party_tp_score']] = party_tp_melted['party_tp'].str.split('+', expand=True)\n",
    "# party_tp_melted['party_tp_score'] = party_tp_melted['party_tp_score'].fillna(0)\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     party_tp_melted, \n",
    "#     left_on=[\"issue_lower\", \"congress\"], \n",
    "#     right_on=[\"英文名称\", \"congress\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "# print(f\"合并政党偏好数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f468b1c",
   "metadata": {},
   "source": [
    "### 4.3 加载国际压力值数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bfe3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intern_pressure_pd = pd.read_excel(\"./input/议题国际压力值.xlsx\", sheet_name=\"Sheet1\")\n",
    "# intern_pressure_pd[\"英文名\"] = intern_pressure_pd[\"英文名\"].apply(lambda x:x.lower())\n",
    "# intern_pressure_pd = intern_pressure_pd.drop(\"政策领域\", axis=1)\n",
    "# intern_pressure_pd = intern_pressure_pd.rename(columns={\"国际压力值\": \"topic_ip\"})\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     intern_pressure_pd, \n",
    "#     left_on=[\"issue_lower\"], \n",
    "#     right_on=[\"英文名\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "# print(f\"合并国际压力值数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ed30a",
   "metadata": {},
   "source": [
    "### 4.4 加载产业卷入度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8171a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# industry_tp_pd = pd.read_excel(\"./input/议题产业卷入度-三组数据.xlsx\",  sheet_name=\"Sheet1\")\n",
    "# industry_tp_pd[\"英文名称\"] = industry_tp_pd[\"英文名称\"].apply(lambda x:x.lower())\n",
    "# industry_tp_pd = industry_tp_pd.drop([\"政策领域\", '118(不带information)', '117(不带information)',\n",
    "#        '116(不带information)', '115(不带information)',  '118(带information)',\n",
    "#         '117(带information)',  '116(带information)',  '115(带information)'], axis=1)\n",
    "# industry_tp_melted = industry_tp_pd.melt(\n",
    "#     id_vars=[\"英文名称\"], \n",
    "#     var_name=\"congress\", \n",
    "#     value_name=\"industry_tp\"\n",
    "# )\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     industry_tp_melted, \n",
    "#     left_on=[\"issue_lower\", \"congress\"], \n",
    "#     right_on=[\"英文名称\", \"congress\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "# print(f\"合并产业卷入度数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b4212",
   "metadata": {},
   "source": [
    "### 4.5 加载国会热度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e965e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# congress_tp_pd = pd.read_excel(\"./input/议题国会热度.xlsx\", sheet_name=\"ByMonth\")\n",
    "# congress_tp_pd.columns = map(str.lower, congress_tp_pd.columns)\n",
    "# congress_tp_pd['date'] = congress_tp_pd['date'].apply(\n",
    "#     lambda x: x.replace(day=1)\n",
    "# )\n",
    "# congress_tp_pd = congress_tp_pd.melt(\n",
    "#     id_vars=[\"date\"], \n",
    "#     var_name=\"issue_lower\", \n",
    "#     value_name=\"congress_tp\"\n",
    "# )\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     congress_tp_pd, \n",
    "#     left_on=[\"date\", \"issue_lower\"], \n",
    "#     right_on=[\"date\", \"issue_lower\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "# print(f\"合并国会热度数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed208f0d",
   "metadata": {},
   "source": [
    "### 4.6 加载白宫热度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17d30d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whitehouse_tp = pd.read_excel(\"./input/议题白宫热度.xlsx\", sheet_name=\"ByMonth\")\n",
    "# whitehouse_tp.columns = map(str.lower, whitehouse_tp.columns)\n",
    "# whitehouse_tp['date'] = whitehouse_tp['date'].apply(\n",
    "#     lambda x: x.replace(day=1)\n",
    "# )\n",
    "# whitehouse_tp = whitehouse_tp.melt(\n",
    "#     id_vars=[\"date\"], \n",
    "#     var_name=\"issue_lower\", \n",
    "#     value_name=\"whitehouse_tp\"\n",
    "# )\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     whitehouse_tp, \n",
    "#     left_on=[\"date\", \"issue_lower\"], \n",
    "#     right_on=[\"date\", \"issue_lower\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "# print(f\"合并白宫热度数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99384759",
   "metadata": {},
   "source": [
    "### 4.7 加载新闻热度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b717338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_tp_pd = pd.read_excel(\"./input/议题新闻热度.xlsx\", sheet_name=\"Sheet1\")\n",
    "# net_tp_pd.columns = map(str.lower, net_tp_pd.columns)\n",
    "# net_tp_pd[\"month\"] = net_tp_pd[\"month\"].apply(\n",
    "#     lambda x: datetime.strptime(str(x), \"%Y%m\").date()\n",
    "# )\n",
    "# net_tp_pd[\"month\"] = pd.to_datetime(net_tp_pd[\"month\"])\n",
    "# net_tp_pd = net_tp_pd.melt(\n",
    "#     id_vars=[\"month\"], \n",
    "#     var_name=\"issue_lower\", \n",
    "#     value_name=\"net_tp\"\n",
    "# )\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     net_tp_pd, \n",
    "#     left_on=[\"date\", \"issue_lower\"], \n",
    "#     right_on=[\"month\", \"issue_lower\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "# print(f\"合并新闻热度数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158ee2e",
   "metadata": {},
   "source": [
    "### 4.8 加载智库热度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "183fdef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thinktant_tp_pd = pd.read_excel(\"./input/议题智库热度.xlsx\", sheet_name=\"Sheet1\")\n",
    "# thinktant_tp_pd.columns = map(str.lower, thinktant_tp_pd.columns)\n",
    "# thinktant_tp_pd[\"month\"] = thinktant_tp_pd[\"month\"].apply(\n",
    "#     lambda x: datetime.strptime(str(x), \"%Y%m\").date()\n",
    "# )\n",
    "# thinktant_tp_pd[\"month\"] = pd.to_datetime(thinktant_tp_pd[\"month\"])\n",
    "# thinktant_tp_pd = thinktant_tp_pd.melt(\n",
    "#     id_vars=[\"month\"], \n",
    "#     var_name=\"issue_lower\", \n",
    "#     value_name=\"thinktant_tp\"\n",
    "# )\n",
    "\n",
    "# train_df = train_df.merge(\n",
    "#     thinktant_tp_pd, \n",
    "#     left_on=[\"date\", \"issue_lower\"], \n",
    "#     right_on=[\"month\", \"issue_lower\"], \n",
    "#     how=\"left\"\n",
    "# )\n",
    "# print(f\"合并智库热度数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e4680",
   "metadata": {},
   "source": [
    "### 4.9 加载族裔卷入度数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdd7e5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并族裔卷入度数据后的规模: (68640, 68)\n"
     ]
    }
   ],
   "source": [
    "zhuyi_issue_pd = pd.read_excel(\"./input/族裔卷入度.xlsx\", sheet_name=\"count\")\n",
    "zhuyi_issue_pd[\"issue\"] = zhuyi_issue_pd[\"issue\"].apply(lambda x:x.lower())\n",
    "zhuyi_issue_melted = zhuyi_issue_pd.melt(id_vars=[\"issue\"], var_name=\"category\", value_name=\"value\")\n",
    "zhuyi_issue_melted[['race', 'congress']] = zhuyi_issue_melted['category'].str.extract(r'([A-Za-z\\s]+)(\\d+)', expand=True)\n",
    "zhuyi_issue_final = zhuyi_issue_melted.pivot(index=['issue', 'congress'], columns='race', values='value').reset_index()\n",
    "zhuyi_issue_final = zhuyi_issue_final[['issue', 'congress', 'White', 'Hispanic OR Latino', 'Black OR African American', \n",
    "                     'American Indian AND Alaska Native', 'Asian', 'Native Hawaiian OR Pacific Islander']]\n",
    "zhuyi_issue_final = zhuyi_issue_final.rename(columns={\"issue\": \"issue_lower\"})\n",
    "zhuyi_issue_final[\"congress\"] = zhuyi_issue_final[\"congress\"].apply(int)\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    zhuyi_issue_final, \n",
    "    left_on=[\"congress\", \"issue_lower\"], \n",
    "    right_on=[\"congress\", \"issue_lower\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "print(f\"合并族裔卷入度数据后的规模: {train_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235dd57b",
   "metadata": {},
   "source": [
    "### 4.10 pvi数据的再匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d029e5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>state_code</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>UT</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>MO</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>CA</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress state_code district\n",
       "0       116         UT       99\n",
       "1       116         MO        4\n",
       "2       115         CA        3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['congress','state_code','district']].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "951804c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pvi = pd.read_excel(DATA_DIR / 'pvi-full-new.xlsx', sheet_name='full')\n",
    "# 提取PVI中的字母部分为ppvi，数字部分为npvi\n",
    "df_pvi['ppvi'] = df_pvi['PVI'].str.extract(r'([A-Za-z]+)')\n",
    "df_pvi['npvi'] = df_pvi['PVI'].str.extract(r'(\\d+)')\n",
    "\n",
    "# 2. 仅保留df_pvi中用于匹配和更新的必要列，使用copy()避免警告\n",
    "df_pvi_sub = df_pvi[['congress', 'postal', 'district', 'ppvi', 'npvi']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1305223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理后df_pvi_sub的规模: (2970, 5)\n",
      "train_df的规模: (68640, 68)\n",
      "\n",
      "合并前train_df中:\n",
      "ppvi缺失值数量: 1280\n",
      "npvi缺失值数量: 3008\n",
      "\n",
      "=== 合并结果统计 ===\n",
      "train_df总行数: 68640\n",
      "合并后ppvi缺失值数量: 736\n",
      "合并后npvi缺失值数量: 2432\n",
      "ppvi成功匹配的数量: 67904\n",
      "npvi成功匹配的数量: 66208\n",
      "ppvi未匹配的数量: 736\n",
      "npvi未匹配的数量: 2432\n"
     ]
    }
   ],
   "source": [
    "# 1. 先处理df_pvi_sub中的district列，将\"AL\"替换为\"At Large\"\n",
    "df_pvi_sub = df_pvi_sub.copy()\n",
    "df_pvi_sub['district'] = df_pvi_sub['district'].replace('AL', 'At Large')\n",
    "\n",
    "# 2. 处理缺失值和数据类型统一\n",
    "# 删除congress为NaN的行\n",
    "df_pvi_sub = df_pvi_sub.dropna(subset=['congress'])\n",
    "\n",
    "# 统一数据类型\n",
    "df_pvi_sub['congress'] = df_pvi_sub['congress'].astype(int)\n",
    "train_df['congress'] = train_df['congress'].astype(int)\n",
    "\n",
    "# 统一字符串格式\n",
    "df_pvi_sub['postal'] = df_pvi_sub['postal'].astype(str).str.strip().str.upper()\n",
    "train_df['state_code'] = train_df['state_code'].astype(str).str.strip().str.upper()\n",
    "df_pvi_sub['district'] = df_pvi_sub['district'].astype(str).str.strip()\n",
    "train_df['district'] = train_df['district'].astype(str).str.strip()\n",
    "\n",
    "print(f\"\\n处理后df_pvi_sub的规模: {df_pvi_sub.shape}\")\n",
    "print(f\"train_df的规模: {train_df.shape}\")\n",
    "\n",
    "# 3. 合并前备份原有的ppvi和npvi值用于比较\n",
    "train_df_before = train_df.copy()\n",
    "original_ppvi_missing = train_df['ppvi'].isna().sum()\n",
    "original_npvi_missing = train_df['npvi'].isna().sum()\n",
    "\n",
    "print(f\"\\n合并前train_df中:\")\n",
    "print(f\"ppvi缺失值数量: {original_ppvi_missing}\")\n",
    "print(f\"npvi缺失值数量: {original_npvi_missing}\")\n",
    "\n",
    "# 4. 执行左连接合并，更新ppvi和npvi\n",
    "train_df = train_df.merge(\n",
    "    df_pvi_sub[['congress', 'postal', 'district', 'ppvi', 'npvi']],\n",
    "    left_on=['congress', 'state_code', 'district'],\n",
    "    right_on=['congress', 'postal', 'district'],\n",
    "    how='left',\n",
    "    suffixes=('', '_new')\n",
    ")\n",
    "\n",
    "# 5. 用新的ppvi和npvi值更新原有值\n",
    "# 首先用新值覆盖原值（包括非空值）\n",
    "train_df['ppvi'] = train_df['ppvi_new']\n",
    "train_df['npvi'] = train_df['npvi_new']\n",
    "\n",
    "# 6. 删除合并产生的多余列\n",
    "train_df = train_df.drop(columns=['ppvi_new', 'npvi_new', 'postal'])\n",
    "\n",
    "# 7. 计算匹配统计\n",
    "after_ppvi_missing = train_df['ppvi'].isna().sum()\n",
    "after_npvi_missing = train_df['npvi'].isna().sum()\n",
    "\n",
    "matched_ppvi = original_ppvi_missing - after_ppvi_missing + (len(train_df) - original_ppvi_missing)\n",
    "matched_npvi = original_npvi_missing - after_npvi_missing + (len(train_df) - original_npvi_missing)\n",
    "\n",
    "print(f\"\\n=== 合并结果统计 ===\")\n",
    "print(f\"train_df总行数: {len(train_df)}\")\n",
    "print(f\"合并后ppvi缺失值数量: {after_ppvi_missing}\")\n",
    "print(f\"合并后npvi缺失值数量: {after_npvi_missing}\")\n",
    "print(f\"ppvi成功匹配的数量: {len(train_df) - after_ppvi_missing}\")\n",
    "print(f\"npvi成功匹配的数量: {len(train_df) - after_npvi_missing}\")\n",
    "print(f\"ppvi未匹配的数量: {after_ppvi_missing}\")\n",
    "print(f\"npvi未匹配的数量: {after_npvi_missing}\")\n",
    "\n",
    "# # 8. 详细分析未匹配的数据\n",
    "# unmatched_data = train_df[train_df['ppvi'].isna()]\n",
    "# if len(unmatched_data) > 0:\n",
    "#     print(f\"\\n=== 未匹配数据分析 ===\")\n",
    "#     print(f\"未匹配数据总数: {len(unmatched_data)}\")\n",
    "#     print(\"\\n未匹配数据的congress分布:\")\n",
    "#     print(unmatched_data['congress'].value_counts().sort_index())\n",
    "#     print(\"\\n未匹配数据的state_code分布:\")\n",
    "#     print(unmatched_data['state_code'].value_counts())\n",
    "#     print(\"\\n未匹配数据的district分布:\")\n",
    "#     print(unmatched_data['district'].value_counts())\n",
    "    \n",
    "#     # 显示几个未匹配的样例\n",
    "#     print(\"\\n未匹配数据样例:\")\n",
    "#     print(unmatched_data[['congress', 'state_code', 'district', 'ppvi', 'npvi']].head())\n",
    "# else:\n",
    "#     print(f\"\\n所有数据都成功匹配!\")\n",
    "\n",
    "# # 9. 验证匹配效果\n",
    "# print(f\"\\n=== 匹配效果验证 ===\")\n",
    "# print(f\"匹配率: {((len(train_df) - after_ppvi_missing) / len(train_df) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f013a3",
   "metadata": {},
   "source": [
    "## 特征筛选与数据存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c681111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修正列名\n",
    "train_df = train_df.rename(columns={\n",
    "    \"参议院委员会\": \"s_committee_tp\",\n",
    "    \"众议院委员会\":\"h_committee_tp\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "132ee41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择最终所需的特征列\n",
    "train_df = train_df[[\n",
    "    \"issue\", \"mid\", \"full_name\", \"chamber\",\n",
    "    \"age\", \"party\", \"state_code\", \"gender\", \"congress\",\n",
    "    \"committee_el\", \"com_post\",\n",
    "    \"district\",    # 补充选区的数据\n",
    "    \"ideology\",    # 补充意识形态的数据\n",
    "    \"seniority\",   # 资历\n",
    "    \n",
    "    # 时间信息\n",
    "    # \"cur_year\", \"cur_month\",\n",
    "    \n",
    "    # 选区层面\n",
    "    \"ppvi\", \"npvi\",\n",
    "    \"employ1\", \"employ2\", \"employ3\", \n",
    "    \"payroll1\", \"payroll2\", \"payroll3\",\n",
    "    \"ethnicity1\", \"ethnicity2\", \"ethnicity3\",\n",
    "\n",
    "    # # 州层面\n",
    "    'state_ppvi', 'state_npvi',\n",
    "    # 'state_employ1', 'state_employ2', 'state_employ3',\n",
    "    # 'state_payroll1','state_payroll2', 'state_payroll3',\n",
    "    # 'state_ethnicity1','state_ethnicity2', 'state_ethnicity3',\n",
    "\n",
    "    # 政党议题偏好、国际压力值、产业卷入度\n",
    "    'h_committee_tp1', 'h_committee_tp2', 'h_committee_tp3',\n",
    "    's_committee_tp1', 's_committee_tp2', 's_committee_tp3',\n",
    "    'party_tp_type', 'party_tp_score', 'party_tp', 'industry_tp1',\n",
    "    'industry_tp2', 'industry_tp3', 'ethnicity_tp1', 'ethnicity_tp2',\n",
    "    'ethnicity_tp3', '国际压力值',\n",
    "\n",
    "    # 热度数据\n",
    "    # 'congress_tp', 'whitehouse_tp','net_tp','thinktant_tp',\n",
    "     \n",
    "     \n",
    "    # \"White\", \"Hispanic OR Latino\",\n",
    "    # \"Black OR African American\", \"American Indian AND Alaska Native\",\n",
    "    # \"Asian\", \"Native Hawaiian OR Pacific Islander\",\n",
    "     \n",
    "    # 标签\n",
    "    \"label\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4eefa071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存最终数据到CSV文件\n",
    "output_file = TRAIN_DATA_DIR / \"legis_train_data_with_feature_更新test.csv\"\n",
    "train_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ec6e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取的数据形状: (68640, 44)\n"
     ]
    }
   ],
   "source": [
    "# 测试加载保存的数据\n",
    "test_df = pd.read_csv(output_file)\n",
    "print(f\"读取的数据形状: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "71c14c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['issue', 'mid', 'full_name', 'chamber', 'age', 'party', 'state_code',\n",
       "       'gender', 'congress', 'committee_el', 'com_post', 'district',\n",
       "       'ideology', 'seniority', 'ppvi', 'npvi', 'employ1', 'employ2',\n",
       "       'employ3', 'payroll1', 'payroll2', 'payroll3', 'ethnicity1',\n",
       "       'ethnicity2', 'ethnicity3', 'state_ppvi', 'state_npvi',\n",
       "       'h_committee_tp1', 'h_committee_tp2', 'h_committee_tp3',\n",
       "       's_committee_tp1', 's_committee_tp2', 's_committee_tp3',\n",
       "       'party_tp_type', 'party_tp_score', 'party_tp', 'industry_tp1',\n",
       "       'industry_tp2', 'industry_tp3', 'ethnicity_tp1', 'ethnicity_tp2',\n",
       "       'ethnicity_tp3', '国际压力值', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
